{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c9e16d",
   "metadata": {},
   "source": [
    "# CLASSIFICATION-LOGISTIC REGRESSION\n",
    "\n",
    "\n",
    "Keep in mind as you make prediction that predicting an outcome that don't happen can be bad, while failing to predict an outcome that do happen can be fatal(bad also). Clearly, a balance must be found.\n",
    "\n",
    "Logistic regression is better for estimating Boolean outcomes than linear regression because the logistic curve always produces a value between 0 (false) and 1 (true). Anything between these two values can be thought of as a probabilit\n",
    "\n",
    "\n",
    "As logistic regression gives us these probabilities, rather than simple true/false values, we need to take extra steps to convert the result to a category. The simplest way to do this is to apply a threshold. For example, if our threshold is set to 0.5. This means that any y-value below 0.5 is converted to false and any value at above 0.5 is converted to true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc63e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/avalanche.csv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ec1298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>avalanche</th>\n",
       "      <th>no_visitors</th>\n",
       "      <th>surface_hoar</th>\n",
       "      <th>fresh_thickness</th>\n",
       "      <th>wind</th>\n",
       "      <th>weak_layers</th>\n",
       "      <th>tracked_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.900508</td>\n",
       "      <td>8.715485</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.477586</td>\n",
       "      <td>6.801417</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.236594</td>\n",
       "      <td>5.632457</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.244283</td>\n",
       "      <td>9.348871</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.196741</td>\n",
       "      <td>3.782315</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.182905</td>\n",
       "      <td>6.109184</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1091</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.718231</td>\n",
       "      <td>10.426100</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1092</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7.037647</td>\n",
       "      <td>9.741006</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.449889</td>\n",
       "      <td>7.337579</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1094</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.881081</td>\n",
       "      <td>10.457047</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  avalanche  no_visitors  surface_hoar  fresh_thickness  wind  \\\n",
       "0              0          0            4      3.900508         8.715485     6   \n",
       "1              1          0            9      1.477586         6.801417    30   \n",
       "2              2          1            3      3.236594         5.632457     8   \n",
       "3              3          0            0      3.244283         9.348871    12   \n",
       "4              4          1            2      5.196741         3.782315     4   \n",
       "...          ...        ...          ...           ...              ...   ...   \n",
       "1090        1090          1            1      2.182905         6.109184     3   \n",
       "1091        1091          0            2      3.718231        10.426100    28   \n",
       "1092        1092          1            8      7.037647         9.741006    34   \n",
       "1093        1093          0            2      2.449889         7.337579    37   \n",
       "1094        1094          1            3      4.881081        10.457047     9   \n",
       "\n",
       "      weak_layers  tracked_out  \n",
       "0               9            0  \n",
       "1               0            0  \n",
       "2               8            1  \n",
       "3              10            0  \n",
       "4               9            1  \n",
       "...           ...          ...  \n",
       "1090            9            0  \n",
       "1091            0            0  \n",
       "1092            3            0  \n",
       "1093           10            1  \n",
       "1094            7            0  \n",
       "\n",
       "[1095 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172dc33e",
   "metadata": {},
   "source": [
    "# Data Explorartion\n",
    "\n",
    "# Box plot for grouping variable\n",
    "\n",
    "Now let's plot the relationships between each feature and the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9657507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='avalanche', ylabel='surface_hoar'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#fig, ax = plt.subplots()\n",
    "\n",
    "# Add a boxplot for the \"bmi\" column in the DataFrames\n",
    "#ax.boxplot([dataset[\"surface_hoar\"], dataset[\"fresh_thickness\"]])\n",
    "\n",
    "import seaborn as sns\n",
    "sns.boxplot( x=dataset[\"avalanche\"], y=dataset[\"surface_hoar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f5c51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='avalanche', ylabel='no_visitors'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot( x=dataset[\"avalanche\"], y=dataset[\"no_visitors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d9264b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='avalanche', ylabel='fresh_thickness'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot( x=dataset[\"avalanche\"], y=dataset[\"fresh_thickness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68dcdd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='avalanche', ylabel='weak_layers'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot( x=dataset[\"avalanche\"], y=dataset[\"weak_layers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fresh_thickness the outcomes are very similar. This means that variations in their values aren't strongly correlated with the results.\n",
    "\n",
    "# Variations in values for weak_layers and no_visitors, seem to correlate with a \n",
    "# larger number of avalanche results, and thus we should assign more importance to these features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed65b78",
   "metadata": {},
   "source": [
    "# Build a simple model using statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "946281fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(766, 8)\n",
      "(329, 8)\n"
     ]
    }
   ],
   "source": [
    "# Here we import a function that splits datasets according to a given ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset in an 70/30 train/test ratio. \n",
    "train, test = train_test_split(dataset, test_size=0.3, random_state=2)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eac540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model with only one predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56484114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.631451\n",
      "         Iterations 5\n",
      "Model trained\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Perform logistic regression.\n",
    "model = smf.logit(\"avalanche ~ weak_layers\", train).fit()\n",
    "\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55b1ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              avalanche   No. Observations:                  766\n",
      "Model:                          Logit   Df Residuals:                      764\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Fri, 08 Oct 2021   Pseudo R-squ.:                 0.07898\n",
      "Time:                        11:21:09   Log-Likelihood:                -483.69\n",
      "converged:                       True   LL-Null:                       -525.17\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.395e-20\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      -0.8586      0.147     -5.856      0.000      -1.146      -0.571\n",
      "weak_layers     0.2241      0.026      8.648      0.000       0.173       0.275\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the positive coefficient for weak_layers means that \n",
    "# a higher value means a higher likelihood for an avalanche\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7c461c",
   "metadata": {},
   "source": [
    "# Use our trained Models to make predictions and estimate probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de5b230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A weak_layer with value 5 yields a 56.51% chance of an avalanche.\n",
      "A weak_layer with value 4 yields a 50.95% chance of an avalanche.\n",
      "A weak_layer with value 7 yields a 67.05% chance of an avalanche.\n",
      "A weak_layer with value 0 yields a 29.76% chance of an avalanche.\n"
     ]
    }
   ],
   "source": [
    "# predict to get a probability\n",
    "\n",
    "# get first 3 samples from dataset\n",
    "samples = test[\"weak_layers\"][:4]\n",
    "\n",
    "# use the model to get predictions as possibilities\n",
    "estimated_probabilities = model.predict(samples)\n",
    "\n",
    "# Print results for each sample\n",
    "for sample, pred in zip(samples,estimated_probabilities):\n",
    "    print(f\"A weak_layer with value {sample} yields a {pred * 100:.2f}% chance of an avalanche.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a48d50ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function <lambda> at 0x7fafad2f9dc0>\n"
     ]
    }
   ],
   "source": [
    "# plot the model\n",
    "# this plots the predicted probabilites given the week_layers\n",
    "predict = lambda x: model.predict(pandas.DataFrame({\"weak_layers\": x}))\n",
    "\n",
    "#graphing.line_2D([(\"Model\", predict)],\n",
    "                 #x_range=[-20,40],\n",
    "                 #label_x=\"weak_layers\", \n",
    "                 #label_y=\"estimated probability of an avalanche\")\n",
    "\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f49ccea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.761071\n",
       "1       0.297630\n",
       "2       0.717973\n",
       "3       0.799423\n",
       "4       0.761071\n",
       "          ...   \n",
       "1090    0.761071\n",
       "1091    0.297630\n",
       "1092    0.453579\n",
       "1093    0.799423\n",
       "1094    0.670468\n",
       "Length: 1095, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # use the model to get predictions as possibilities\n",
    "pred_prob = model.predict(dataset['weak_layers'])\n",
    "pred_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f11e2201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c759968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of weak layers: 0\n",
      "Maximum number of weak layers: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum number of weak layers:\", min(train.weak_layers))\n",
    "print(\"Maximum number of weak layers:\", max(train.weak_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f26ecd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rate of avalanches for 0 weak layers of snow 0.3880597014925373\n",
      "Average rate of avalanches for 10 weak layers of snow 0.7761194029850746\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get actual rates of avalanches at 0 years\n",
    "avalanche_outcomes_for_0_layers = train[train.weak_layers == 0].avalanche\n",
    "print(\"Average rate of avalanches for 0 weak layers of snow\", np.average(avalanche_outcomes_for_0_layers))\n",
    "\n",
    "# Get actual rates of avalanches at 10 years\n",
    "avalanche_outcomes_for_10_layers = train[train.weak_layers == 10].avalanche\n",
    "print(\"Average rate of avalanches for 10 weak layers of snow\", np.average(avalanche_outcomes_for_10_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1866c8a",
   "metadata": {},
   "source": [
    "# Classification or decision thresholds\n",
    "To return a binary category (True = \"avalanche\", False = \"no avalanche\") we need to define a Classification Threshold value. Any probability above that threshold is returned as the positive category, whereas values below it will be returned as the negative category.\n",
    "\n",
    "Let's see what happens if set our threshold to 0.5 (meaning that our model will return True whenever it calculates a chance above 50% of an avalanche happening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11afe4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A weak_layer with value 5 yields a chance of 76.11% of an avalanche. Classification = True\n",
      "A weak_layer with value 4 yields a chance of 29.76% of an avalanche. Classification = False\n",
      "A weak_layer with value 7 yields a chance of 71.80% of an avalanche. Classification = True\n",
      "A weak_layer with value 0 yields a chance of 79.94% of an avalanche. Classification = True\n"
     ]
    }
   ],
   "source": [
    "# threshold to get an absolute value\n",
    "threshold = 0.5\n",
    "\n",
    "# Add classification to the samples we used before\n",
    "for sample, pred in list(zip(samples,estimated_probabilities)):\n",
    "    print(f\"A weak_layer with value {sample} yields a chance of {pred * 100:.2f}% of an avalanche. Classification = {pred > threshold}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e682c70",
   "metadata": {},
   "source": [
    "# Performance on test set\n",
    "Now let's use our test dataset to perform a quick evaluation on how the model did. \n",
    "\n",
    "For now, we'll just look at how often we correctly predicted if there would be an avalanche or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d54060e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model correctly predicted outcomes 65.05% of time.\n"
     ]
    }
   ],
   "source": [
    "# Classify the mdel predictions using the threshold\n",
    "predictions = model.predict(test) > threshold\n",
    "\n",
    "# Compare the predictions to the actual outcomes in the dataset\n",
    "accuracy = np.average(predictions == test.avalanche)\n",
    "\n",
    "# Print the evaluation\n",
    "print(f\"The model correctly predicted outcomes {accuracy * 100:.2f}% of time.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02005ff0",
   "metadata": {},
   "source": [
    "# Assessing a classification model\n",
    "\n",
    "Assessing model visually\n",
    "\n",
    "Sometimes, but not always, we can visually assess a logistic regression mode. Let's plot our model against the actual data in the test dataset\n",
    "\n",
    "Remember that during training, we calculate how badly a model performs, and call this cost, or loss.\n",
    "\n",
    "Using the final labels for a cost function is more useful if we want to estimate the real-world performance of our model, for instance, on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1062b59b",
   "metadata": {},
   "source": [
    "# Logg Loss function\n",
    "Log loss is one of the most popular cost functions for simple classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f18efeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weak_layers):\n",
    "    return model.predict(dict(weak_layers=weak_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e242a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efa96aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>avalanche</th>\n",
       "      <th>no_visitors</th>\n",
       "      <th>surface_hoar</th>\n",
       "      <th>fresh_thickness</th>\n",
       "      <th>wind</th>\n",
       "      <th>weak_layers</th>\n",
       "      <th>tracked_out</th>\n",
       "      <th>predic</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.900508</td>\n",
       "      <td>8.715485</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.761071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.477586</td>\n",
       "      <td>6.801417</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.297630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.236594</td>\n",
       "      <td>5.632457</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.717973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.244283</td>\n",
       "      <td>9.348871</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.799423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.196741</td>\n",
       "      <td>3.782315</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.761071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.182905</td>\n",
       "      <td>6.109184</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.761071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1091</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.718231</td>\n",
       "      <td>10.426100</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.297630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1092</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7.037647</td>\n",
       "      <td>9.741006</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.453579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.449889</td>\n",
       "      <td>7.337579</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.799423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1094</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.881081</td>\n",
       "      <td>10.457047</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.670468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  avalanche  no_visitors  surface_hoar  fresh_thickness  wind  \\\n",
       "0              0          0            4      3.900508         8.715485     6   \n",
       "1              1          0            9      1.477586         6.801417    30   \n",
       "2              2          1            3      3.236594         5.632457     8   \n",
       "3              3          0            0      3.244283         9.348871    12   \n",
       "4              4          1            2      5.196741         3.782315     4   \n",
       "...          ...        ...          ...           ...              ...   ...   \n",
       "1090        1090          1            1      2.182905         6.109184     3   \n",
       "1091        1091          0            2      3.718231        10.426100    28   \n",
       "1092        1092          1            8      7.037647         9.741006    34   \n",
       "1093        1093          0            2      2.449889         7.337579    37   \n",
       "1094        1094          1            3      4.881081        10.457047     9   \n",
       "\n",
       "      weak_layers  tracked_out                                 predic  \\\n",
       "0               9            0  <function <lambda> at 0x7fafad030a60>   \n",
       "1               0            0  <function <lambda> at 0x7fafad030a60>   \n",
       "2               8            1  <function <lambda> at 0x7fafad030a60>   \n",
       "3              10            0  <function <lambda> at 0x7fafad030a60>   \n",
       "4               9            1  <function <lambda> at 0x7fafad030a60>   \n",
       "...           ...          ...                                    ...   \n",
       "1090            9            0  <function <lambda> at 0x7fafad030a60>   \n",
       "1091            0            0  <function <lambda> at 0x7fafad030a60>   \n",
       "1092            3            0  <function <lambda> at 0x7fafad030a60>   \n",
       "1093           10            1  <function <lambda> at 0x7fafad030a60>   \n",
       "1094            7            0  <function <lambda> at 0x7fafad030a60>   \n",
       "\n",
       "      predictions  \n",
       "0        0.761071  \n",
       "1        0.297630  \n",
       "2        0.717973  \n",
       "3        0.799423  \n",
       "4        0.761071  \n",
       "...           ...  \n",
       "1090     0.761071  \n",
       "1091     0.297630  \n",
       "1092     0.453579  \n",
       "1093     0.799423  \n",
       "1094     0.670468  \n",
       "\n",
       "[1095 rows x 10 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding predictons to the data set\n",
    "\n",
    "dataset['predictions'] = predict(dataset['weak_layers'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a71e4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plotting delta_fvc vs fibro_6m\n",
    "ax.scatter(dataset[\"weak_layers\"], dataset[\"predictions\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c666c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the earlier graph, we can see that our model will predict an avalanche when the number of weak layers of snow is greater than 5. We can tell this because the value of the line is 0.5 at x=5 (remember that in the previous \n",
    "# unit we defined a classifier threshold, so that probabilities over 0.5 would be classified as True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af994fa",
   "metadata": {},
   "source": [
    "# Assess with cost function\n",
    "Let's assess our model with a log-loss cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e67921f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss 0.6308523505726719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Make predictions from the test set\n",
    "predictions = model.predict(test)\n",
    "\n",
    "# Calculate log loss\n",
    "print(\"Log loss\", log_loss(test.avalanche, predictions))\n",
    "# 0.66 - what does that mean? This could be useful to compare two different models, \n",
    "# but it's hard to get a grasp on exactly what this means for real-world performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fba587",
   "metadata": {},
   "source": [
    "# Assess accuracy\n",
    "\n",
    "#Let's instead assess accuracy. Accuracy refers to the proportion of predictions \n",
    "#the model got correct, after predictions are converted from probabilities to avalanche or no-avalanche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf363ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First three predictions (probabilities): 0.5651379879785626, 0.509476679940887, 0.6704676581785758\n",
      "First three predictions (categories): True, True, True\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "# Print a few predictions before we convert them to categories\n",
    "print(f\"First three predictions (probabilities): {predictions.iloc[0]}, {predictions.iloc[1]}, {predictions.iloc[2]}\")\n",
    "\n",
    "# convert to absolute values\n",
    "avalanche_predicted = predictions >= 0.5\n",
    "\n",
    "# Print a few predictions converted into categories\n",
    "print(f\"First three predictions (categories): {avalanche_predicted.iloc[0]}, {avalanche_predicted.iloc[1]}, {avalanche_predicted.iloc[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84505820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for whole test dataset: 0.6504559270516718\n"
     ]
    }
   ],
   "source": [
    "# Calculate what proportion were predicted correctly\n",
    "guess_was_correct = test.avalanche == avalanche_predicted\n",
    "accuracy = numpy.average(guess_was_correct)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy for whole test dataset:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It looks like it's predicting the correct answer 61% of the time. This is helpful \n",
    "#information. What kind of mistakes is it making, though? Let's take a look at whether \n",
    "#it is guessing avalanche when there are none (false positives), or failing to guess 'avalanche' \n",
    "# when one actually occurs (false negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1105448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrongly predicted an avalanche 13.069908814589665% of the time\n",
      "Failed to predict avalanches 21.88449848024316% of the time\n"
     ]
    }
   ],
   "source": [
    "# False Positive: calculate how often it guessed avalanche when none actually occurred\n",
    "false_positive = numpy.average(numpy.logical_not(guess_was_correct) & test.avalanche)\n",
    "\n",
    "# False negative: calculate how often it guessed no avalanche, when one actually happened\n",
    "false_negative = numpy.average(numpy.logical_not(guess_was_correct) & numpy.logical_not(test.avalanche))\n",
    "\n",
    "\n",
    "print(f\"Wrongly predicted an avalanche {false_positive * 100}% of the time\")\n",
    "print(f\"Failed to predict avalanches {false_negative * 100}% of the time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57045d",
   "metadata": {},
   "source": [
    "# Improving classification models\n",
    "\n",
    "In our exercises, we found that our model could predict avalanches so some degree, but it was still wrong around 40% of the time. This error amount is because our feature â€“ the number of weak layers of snow â€“ isn't the only thing that is responsible for avalanches.\n",
    "\n",
    "There are two primary ways to improve classification model performance\n",
    "providing additional features and\n",
    "selective about what enters the model\n",
    "\n",
    "Generally, the more features we add to a model, the better the model will work. This is only true, however, if the features we provide are actually relevant and explain something that existing features don't.\n",
    "\n",
    "Yet, if supplied the model will end up modeling a relationship between avalanches and the number of birds spotted on given days. If birds were spotted more on avalanche days, the model will suggest that birds could be responsible for causing avalanches. We might then set up a systematic bird watching program to predict avalanches, only to find it doesn't work at all.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e993649",
   "metadata": {},
   "source": [
    "# simple logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d857104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.631451\n",
      "         Iterations 5\n",
      "Accuracy: 0.6504559270516718\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Perform logistic regression.\n",
    "model = smf.logit(\"avalanche ~ weak_layers\", train).fit()\n",
    "\n",
    "# Calculate accuracy\n",
    "def calculate_accuracy(model):\n",
    "    '''\n",
    "    Calculates accuracy\n",
    "    '''\n",
    "    # Make estimations and convert to categories\n",
    "    avalanche_predicted = model.predict(test) > 0.5\n",
    "\n",
    "    # Calculate what proportion were predicted correctly\n",
    "    # We can use sklearn to calculate accuracy for us\n",
    "    print(\"Accuracy:\", accuracy_score(test.avalanche, avalanche_predicted))\n",
    "\n",
    "calculate_accuracy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd5bd5",
   "metadata": {},
   "source": [
    "# simple logistic regression model\n",
    "\n",
    "# Utilizing multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40df14a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.449626\n",
      "         Iterations 7\n",
      "Accuracy: 0.7750759878419453\n"
     ]
    }
   ],
   "source": [
    "# Perform logistic regression.\n",
    "model_all_features = smf.logit(\"avalanche ~ weak_layers + surface_hoar + fresh_thickness + wind + no_visitors + tracked_out\", train).fit()\n",
    "calculate_accuracy(model_all_features)\n",
    "# below results: That's a big improvement on the simpler model we've been working with.\n",
    "\n",
    "# To understand why, we can look at the summary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f72a8a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>avalanche</td>    <th>  No. Observations:  </th>  <td>   766</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   759</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 08 Oct 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.3442</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:41:29</td>     <th>  Log-Likelihood:    </th> <td> -344.41</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -525.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.212e-75</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>   -4.0774</td> <td>    0.477</td> <td>   -8.540</td> <td> 0.000</td> <td>   -5.013</td> <td>   -3.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weak_layers</th>     <td>    0.3933</td> <td>    0.037</td> <td>   10.749</td> <td> 0.000</td> <td>    0.322</td> <td>    0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surface_hoar</th>    <td>    0.3638</td> <td>    0.038</td> <td>    9.554</td> <td> 0.000</td> <td>    0.289</td> <td>    0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fresh_thickness</th> <td>   -0.0653</td> <td>    0.031</td> <td>   -2.086</td> <td> 0.037</td> <td>   -0.127</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind</th>            <td>    0.1116</td> <td>    0.010</td> <td>   11.215</td> <td> 0.000</td> <td>    0.092</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_visitors</th>     <td>   -0.1204</td> <td>    0.034</td> <td>   -3.497</td> <td> 0.000</td> <td>   -0.188</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tracked_out</th>     <td>   -0.0270</td> <td>    0.190</td> <td>   -0.143</td> <td> 0.887</td> <td>   -0.398</td> <td>    0.344</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              avalanche   No. Observations:                  766\n",
       "Model:                          Logit   Df Residuals:                      759\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Fri, 08 Oct 2021   Pseudo R-squ.:                  0.3442\n",
       "Time:                        14:41:29   Log-Likelihood:                -344.41\n",
       "converged:                       True   LL-Null:                       -525.17\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.212e-75\n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept          -4.0774      0.477     -8.540      0.000      -5.013      -3.142\n",
       "weak_layers         0.3933      0.037     10.749      0.000       0.322       0.465\n",
       "surface_hoar        0.3638      0.038      9.554      0.000       0.289       0.438\n",
       "fresh_thickness    -0.0653      0.031     -2.086      0.037      -0.127      -0.004\n",
       "wind                0.1116      0.010     11.215      0.000       0.092       0.131\n",
       "no_visitors        -0.1204      0.034     -3.497      0.000      -0.188      -0.053\n",
       "tracked_out        -0.0270      0.190     -0.143      0.887      -0.398       0.344\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_features.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95e0ce0",
   "metadata": {},
   "source": [
    "# simplyfying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6822e71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.452522\n",
      "         Iterations 7\n",
      "Accuracy: 0.7750759878419453\n"
     ]
    }
   ],
   "source": [
    "# Perform logistic regression.\n",
    "\n",
    "# getting rid of features with larger p values\n",
    "# tracked_out (how trampled the snow is), and fresh_thickness\n",
    "model_simplified = smf.logit(\"avalanche ~ weak_layers + surface_hoar + wind + no_visitors\", train).fit()\n",
    "calculate_accuracy(model_simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba9bb9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>avalanche</td>    <th>  No. Observations:  </th>  <td>   766</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   759</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 08 Oct 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.3442</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:46:05</td>     <th>  Log-Likelihood:    </th> <td> -344.41</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -525.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.212e-75</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>   -4.0774</td> <td>    0.477</td> <td>   -8.540</td> <td> 0.000</td> <td>   -5.013</td> <td>   -3.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weak_layers</th>     <td>    0.3933</td> <td>    0.037</td> <td>   10.749</td> <td> 0.000</td> <td>    0.322</td> <td>    0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surface_hoar</th>    <td>    0.3638</td> <td>    0.038</td> <td>    9.554</td> <td> 0.000</td> <td>    0.289</td> <td>    0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fresh_thickness</th> <td>   -0.0653</td> <td>    0.031</td> <td>   -2.086</td> <td> 0.037</td> <td>   -0.127</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind</th>            <td>    0.1116</td> <td>    0.010</td> <td>   11.215</td> <td> 0.000</td> <td>    0.092</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_visitors</th>     <td>   -0.1204</td> <td>    0.034</td> <td>   -3.497</td> <td> 0.000</td> <td>   -0.188</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tracked_out</th>     <td>   -0.0270</td> <td>    0.190</td> <td>   -0.143</td> <td> 0.887</td> <td>   -0.398</td> <td>    0.344</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              avalanche   No. Observations:                  766\n",
       "Model:                          Logit   Df Residuals:                      759\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Fri, 08 Oct 2021   Pseudo R-squ.:                  0.3442\n",
       "Time:                        14:46:05   Log-Likelihood:                -344.41\n",
       "converged:                       True   LL-Null:                       -525.17\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.212e-75\n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept          -4.0774      0.477     -8.540      0.000      -5.013      -3.142\n",
       "weak_layers         0.3933      0.037     10.749      0.000       0.322       0.465\n",
       "surface_hoar        0.3638      0.038      9.554      0.000       0.289       0.438\n",
       "fresh_thickness    -0.0653      0.031     -2.086      0.037      -0.127      -0.004\n",
       "wind                0.1116      0.010     11.215      0.000       0.092       0.131\n",
       "no_visitors        -0.1204      0.034     -3.497      0.000      -0.188      -0.053\n",
       "tracked_out        -0.0270      0.190     -0.143      0.887      -0.398       0.344\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_features.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516073ca",
   "metadata": {},
   "source": [
    "# Reflection about model\n",
    "\n",
    "Look at the fresh_thickness row. We're told that it has a negative coefficient. This means that as thickness increases, avalanches decrease.\n",
    "\n",
    "Similarly, no_visitors has a negative coefficient, meaning that fewer hikers means more avalanches.\n",
    "\n",
    "How can this bes? Well, while visitors can cause avalanches if there's a lot of fresh snow, presumably they cannot do so easily if there's no fresh snow. This means that our features aren't fully independent.\n",
    "\n",
    "We can tell the model to try to take into account that these features interact, using a multiply sign. Let's try that now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "859f0632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.396683\n",
      "         Iterations 7\n",
      "Accuracy: 0.7993920972644377\n"
     ]
    }
   ],
   "source": [
    "# Create a model with an interaction. Notice the end of the string where\n",
    "# we've a multiply sign between no_visitors and fresh_thickness\n",
    "formula = \"avalanche ~ weak_layers + surface_hoar + wind + no_visitors * fresh_thickness\"\n",
    "model_with_interaction = smf.logit(formula, train).fit()\n",
    "calculate_accuracy(model_with_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb48743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>avalanche</td>    <th>  No. Observations:  </th>  <td>   766</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   759</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 08 Oct 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.4214</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>14:50:11</td>     <th>  Log-Likelihood:    </th> <td> -303.86</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -525.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.903e-92</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>   -0.5634</td> <td>    0.668</td> <td>   -0.843</td> <td> 0.399</td> <td>   -1.873</td> <td>    0.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>weak_layers</th>                 <td>    0.4566</td> <td>    0.041</td> <td>   11.023</td> <td> 0.000</td> <td>    0.375</td> <td>    0.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>surface_hoar</th>                <td>    0.3973</td> <td>    0.041</td> <td>    9.646</td> <td> 0.000</td> <td>    0.317</td> <td>    0.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wind</th>                        <td>    0.1334</td> <td>    0.012</td> <td>   11.555</td> <td> 0.000</td> <td>    0.111</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_visitors</th>                 <td>   -1.0398</td> <td>    0.124</td> <td>   -8.396</td> <td> 0.000</td> <td>   -1.283</td> <td>   -0.797</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fresh_thickness</th>             <td>   -0.5822</td> <td>    0.075</td> <td>   -7.732</td> <td> 0.000</td> <td>   -0.730</td> <td>   -0.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_visitors:fresh_thickness</th> <td>    0.1114</td> <td>    0.014</td> <td>    7.992</td> <td> 0.000</td> <td>    0.084</td> <td>    0.139</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              avalanche   No. Observations:                  766\n",
       "Model:                          Logit   Df Residuals:                      759\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Fri, 08 Oct 2021   Pseudo R-squ.:                  0.4214\n",
       "Time:                        14:50:11   Log-Likelihood:                -303.86\n",
       "converged:                       True   LL-Null:                       -525.17\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.903e-92\n",
       "===============================================================================================\n",
       "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                      -0.5634      0.668     -0.843      0.399      -1.873       0.746\n",
       "weak_layers                     0.4566      0.041     11.023      0.000       0.375       0.538\n",
       "surface_hoar                    0.3973      0.041      9.646      0.000       0.317       0.478\n",
       "wind                            0.1334      0.012     11.555      0.000       0.111       0.156\n",
       "no_visitors                    -1.0398      0.124     -8.396      0.000      -1.283      -0.797\n",
       "fresh_thickness                -0.5822      0.075     -7.732      0.000      -0.730      -0.435\n",
       "no_visitors:fresh_thickness     0.1114      0.014      7.992      0.000       0.084       0.139\n",
       "===============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_interaction.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de2a253",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION with scikit-learn- datacamp\n",
    "\n",
    "conditions for using  scikit-learn API\n",
    "\n",
    "1 The features need to be in an array where each column is a feature and each row a different observation or data point - \n",
    "The target needs to be a single column with the same number of observations as the feature data. \n",
    "\n",
    "Note the use of .drop() to drop the target variable 'avalance' from the feature array X as well as the use of the .values attribute to ensure X and y are NumPy arrays.\n",
    "\n",
    "Without using .values, X and y are a DataFrame and Series respectively; \n",
    "\n",
    "the scikit-learn API will accept them in this form also as long as they are of the right shape.\n",
    "\n",
    "there must not be amnu m issimng values in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61e180d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>avalanche</th>\n",
       "      <th>no_visitors</th>\n",
       "      <th>surface_hoar</th>\n",
       "      <th>fresh_thickness</th>\n",
       "      <th>wind</th>\n",
       "      <th>weak_layers</th>\n",
       "      <th>tracked_out</th>\n",
       "      <th>predic</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.900508</td>\n",
       "      <td>8.715485</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.761071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.477586</td>\n",
       "      <td>6.801417</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.297630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.236594</td>\n",
       "      <td>5.632457</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.717973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.244283</td>\n",
       "      <td>9.348871</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.799423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.196741</td>\n",
       "      <td>3.782315</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.761071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.182905</td>\n",
       "      <td>6.109184</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.761071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>1091</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.718231</td>\n",
       "      <td>10.426100</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.297630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1092</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7.037647</td>\n",
       "      <td>9.741006</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.453579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.449889</td>\n",
       "      <td>7.337579</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.799423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1094</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.881081</td>\n",
       "      <td>10.457047</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function &lt;lambda&gt; at 0x7fafad030a60&gt;</td>\n",
       "      <td>0.670468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  avalanche  no_visitors  surface_hoar  fresh_thickness  wind  \\\n",
       "0              0          0            4      3.900508         8.715485     6   \n",
       "1              1          0            9      1.477586         6.801417    30   \n",
       "2              2          1            3      3.236594         5.632457     8   \n",
       "3              3          0            0      3.244283         9.348871    12   \n",
       "4              4          1            2      5.196741         3.782315     4   \n",
       "...          ...        ...          ...           ...              ...   ...   \n",
       "1090        1090          1            1      2.182905         6.109184     3   \n",
       "1091        1091          0            2      3.718231        10.426100    28   \n",
       "1092        1092          1            8      7.037647         9.741006    34   \n",
       "1093        1093          0            2      2.449889         7.337579    37   \n",
       "1094        1094          1            3      4.881081        10.457047     9   \n",
       "\n",
       "      weak_layers  tracked_out                                 predic  \\\n",
       "0               9            0  <function <lambda> at 0x7fafad030a60>   \n",
       "1               0            0  <function <lambda> at 0x7fafad030a60>   \n",
       "2               8            1  <function <lambda> at 0x7fafad030a60>   \n",
       "3              10            0  <function <lambda> at 0x7fafad030a60>   \n",
       "4               9            1  <function <lambda> at 0x7fafad030a60>   \n",
       "...           ...          ...                                    ...   \n",
       "1090            9            0  <function <lambda> at 0x7fafad030a60>   \n",
       "1091            0            0  <function <lambda> at 0x7fafad030a60>   \n",
       "1092            3            0  <function <lambda> at 0x7fafad030a60>   \n",
       "1093           10            1  <function <lambda> at 0x7fafad030a60>   \n",
       "1094            7            0  <function <lambda> at 0x7fafad030a60>   \n",
       "\n",
       "      predictions  \n",
       "0        0.761071  \n",
       "1        0.297630  \n",
       "2        0.717973  \n",
       "3        0.799423  \n",
       "4        0.761071  \n",
       "...           ...  \n",
       "1090     0.761071  \n",
       "1091     0.297630  \n",
       "1092     0.453579  \n",
       "1093     0.799423  \n",
       "1094     0.670468  \n",
       "\n",
       "[1095 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c8b91a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1207641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import KNeighborsClassifier from sklearn.neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "# Create arrays for the features and the response variable\n",
    "# the features must be only continous variables, so im dropping all the other cat features and creating a new df with \n",
    "# just the target label and cont features. cat varaibles will be dealth with later\n",
    "df = dataset[['avalanche', 'surface_hoar','fresh_thickness','weak_layers','wind']]\n",
    "y = df['avalanche'].values\n",
    "X = df.drop('avalanche', axis=1).values\n",
    "\n",
    "# Create a k-NN classifier with 6 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a8ab9",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors: Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abc7eb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1 0 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict the labels for the training data X: y_pred\n",
    "# here we are predicting using the same training data, but ideally, we should be predicting on the test dataset after test train split\n",
    "y_pred = knn.predict(X)\n",
    "print(\"Prediction: {}\".format(y_pred))\n",
    "\n",
    "# Predict and print the label for the new data point X_new\n",
    "#new_prediction = knn.predict(X_new)\n",
    "#print(\"Prediction New: {}\".format(new_prediction)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b94db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6dae6818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 3, ..., 8, 2, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = dataset['no_visitors'].values\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40933eaf",
   "metadata": {},
   "source": [
    "# ACCURACY AND MODEL COMPLEXITY CURVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a0df2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the digits dataset: digits\n",
    "digits = datasets.load_digits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d08ffc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i will be using the df for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa6e273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7351598173515982\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create feature and target arrays\n",
    "y = df['avalanche'].values\n",
    "X = df.drop('avalanche', axis=1).values\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y) # stratify = 1 ensures that\n",
    "# the labels in both traing and test set are equally distributed as thet were in the original data set\n",
    "\n",
    "# Create a k-NN classifier with 7 neighbors: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(knn.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07704be",
   "metadata": {},
   "source": [
    "# Overfitting and underfitting\n",
    "if decision boundary is smooth, then  the model is less complesx as is what we want generally and the decision boundary becomes smooth generally for larger k values. this results to underfitting as not all points are captured\n",
    "\n",
    "if k is small, then the decisoon boundar is generaly rough and no smooth, this is suggesting a very complex model and the model tries to  capture every data point  and this resukts to over fitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6bbdf",
   "metadata": {},
   "source": [
    "Task is to compute accuracy, compute and plot the training and testing accuracy scores for a variety of different neighbor values( values of k). By observing how the accuracy scores differ for the training and testing sets with different values of k, you will develop your intuition for overfitting and underfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23f72ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup arrays to store train and test accuracies\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "# Loop over different values of k\n",
    "for i, k in enumerate(neighbors):\n",
    "    # Setup a k-NN Classifier with k neighbors: knn\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)\n",
    "\n",
    "# Generate plot\n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478d75ac",
   "metadata": {},
   "source": [
    "# comparing model complexity curves will give you an idea of the best number of neighbours to use so as to avoid under/overfitting\n",
    "#  in this case, 3 to  5 seems to the best number of neighbours. this should correspond to where the accuracu score is highest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8322a958",
   "metadata": {},
   "source": [
    "# class imbalance\n",
    "\n",
    "Accuracy is not always a correct matrics to use to measure model performance in cases where there is class imbalance\n",
    "\n",
    "e.g in a spam priblem,. 99% of emaills are real and only 1% are false(spam)\n",
    "such a model will classify all emails as real and would be correct 99% of the time with an accuracy of 99%\n",
    "\n",
    "there is class imbalance here as the class of real emails contain way more classes than the class of spams\n",
    "In this case, a different mnatrics other than accuracy is required to assess performance\n",
    "\n",
    "a confusion matrix can be called which also has accuracy embeddded in it\n",
    "\n",
    "the category thatb you are trying toi detect is called the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c8f81b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[160  38]\n",
      " [ 75 165]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74       198\n",
      "           1       0.81      0.69      0.74       240\n",
      "\n",
      "    accuracy                           0.74       438\n",
      "   macro avg       0.75      0.75      0.74       438\n",
      "weighted avg       0.75      0.74      0.74       438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Instantiate a k-NN classifier: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdf648a",
   "metadata": {},
   "source": [
    "# Logistic regression using scikitlearn\n",
    "\n",
    "#used in classification problemns, not regression problems\n",
    "\n",
    "generally, we use as default threshold of prob = 0.5\n",
    "if prob = 0., model predicts 1 for all the data points, meaning true positive = false positive\n",
    "of prob  = 1, the model predicts 0 for all the data, meaning both true and false positive are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40782929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147  51]\n",
      " [ 49 191]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75       198\n",
      "           1       0.79      0.80      0.79       240\n",
      "\n",
      "    accuracy                           0.77       438\n",
      "   macro avg       0.77      0.77      0.77       438\n",
      "weighted avg       0.77      0.77      0.77       438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaee5b4",
   "metadata": {},
   "source": [
    "# ROC Curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1b45e42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "# unpack the output of this into the variables\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e269c58a",
   "metadata": {},
   "source": [
    "# AREA UNDER A CURVE\n",
    "\n",
    " THE BIGGER THE AUC VALUE, THE BETTER THE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92e26fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8442340067340067\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob: .predict_proba() method on logreg to compute the predicted probabilitie\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83d5c95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC scores computed using 5-fold cross-validation: [0.84980604 0.85152949 0.82246071 0.86758492 0.86564137]\n"
     ]
    }
   ],
   "source": [
    "# WE CAN ALSO COMPUTE AUC FOR CROSS VALIDATION\n",
    "\n",
    "# Compute cross-validated AUC scores: cv_auc\n",
    "cv_auc = cross_val_score(logreg, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))\n",
    "\n",
    "# we can later calculate the mean and sd of these 5 auc values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f08df9",
   "metadata": {},
   "source": [
    "# HYparameter Tuniung- GRID SEARC CROSS VALIDATION\n",
    "\n",
    "when fitting a model, we have to choose values that fits the data well and thise values are nvere learnit by the model\n",
    "so we specify these parameters e.g alpha for lasso/ridge regression, n for knn neighbours\n",
    "we generally have to try all these values, fit them separately and see how each one porforms and then choose the best one. We always use cross validadtion when trying different sets of hyper parameters\n",
    "we choose a grid of possible values we wasnt to try for the hyperparameters and then nlater choose the parameters the performs best. This is called Grid Search Cross validation\n",
    "\n",
    "logistic regression also has a regularization parameter: . C controls the inverse of the regularization strength, and this is what you will tune in this exercise\n",
    "\n",
    "A large C can lead to an overfit model, while a small C can lead to an underfit model.\n",
    "\n",
    "In practice, you will indeed want to hold out a portion of your data for evaluation purposes, and you will learn all about this in the next , the below script doesnt show any hold out set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8d9426fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 0.4393970560760795}\n",
      "Best score is 0.7689497716894976\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}  # this is a dictionarty of the parameters\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X, y)\n",
    "\n",
    "# Print the tuned parameter and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f5b8c",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with RandomizedSearchCV\n",
    "\n",
    "GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space and dealing with multiple hyperparameters. A solution to this is to use RandomizedSearchCV, in which not all hyperparameter values are tried out. Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "078ee989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'gini', 'max_depth': None, 'max_features': 4, 'min_samples_leaf': 7}\n",
      "Best score is 0.7351598173515981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 289, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.73515982        nan        nan 0.67853881 0.67305936\n",
      "        nan 0.73333333        nan 0.6739726 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "# Decision trees have many parameters that can be tuned, such as max_features, max_depth, and min_samples_leaf\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "\n",
    "\n",
    "# NB Note that RandomizedSearchCV will never outperform GridSearchCV. \n",
    "#Instead, it is valuable because it saves on computation time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee6d8c",
   "metadata": {},
   "source": [
    "# Hold-out set for final evaluation\n",
    "\n",
    " after performing cross validation, we neede to report how well out model perfoms on data it has never seen before\n",
    " \n",
    " using all data for cross validation is not ideal, so we need to split the data into training set and hold outr set\n",
    " \n",
    " trainng model on training set and select parameters on traimning set\n",
    " use hold out set to test model performance\n",
    " \n",
    " =========================\n",
    " \n",
    " In addition to , logistic regression has a 'penalty' hyperparameter which specifies whether to use 'l1' or 'l2' regularization. Your job in this exercise is to create a hold-out set, tune the 'C' and 'penalty' hyperparameters of a logistic regression classifier using GridSearchCV on the training set.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "19b84f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 0.006105402296585327, 'penalty': 'l2'}\n",
      "Tuned Logistic Regression Accuracy: 0.7746819338422392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/uczhn/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.561647          nan 0.69245894        nan 0.73972935\n",
      "        nan 0.77468193        nan 0.77011335        nan 0.77468193\n",
      "        nan 0.77468193        nan 0.77468193        nan 0.77468193\n",
      "        nan 0.77468193        nan 0.77468193        nan 0.77468193\n",
      "        nan 0.77468193        nan 0.77468193        nan 0.77468193]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "# Tune the hyperparameters on the training set using GridSearchCV with 5-folds.\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "# Use the following format to access an attribute of an object: object_name.attribute_name. \n",
    "#For example: logreg_cv.best_score_.\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9e1d6",
   "metadata": {},
   "source": [
    "# Elastic net regressor- extra stuff\n",
    "\n",
    "Hold-out set in practice II: Regression\n",
    "Remember lasso and ridge regression from the previous chapter? Lasso used the  penalty to regularize, while ridge used the  penalty. There is another type of regularized regression known as the elastic net. In elastic net regularization, the penalty term is a linear combination of the  and  penalties:\n",
    "\n",
    "\n",
    "In scikit-learn, this term is represented by the 'l1_ratio' parameter: An 'l1_ratio' of 1 corresponds to an  penalty, and anything lower is a combination of  and .\n",
    "\n",
    "In this exercise, you will GridSearchCV to tune the 'l1_ratio' of an elastic net model trained on the Gapminder data. As in the previous exercise, use a hold-out set to evaluate your model's performance.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61179f43",
   "metadata": {},
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "l1_space = np.linspace(0, 1, 30)\n",
    "param_grid = {'l1_ratio': l1_space}\n",
    "\n",
    "# Instantiate the ElasticNet regressor: elastic_net\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Setup the GridSearchCV object: gm_cv\n",
    "gm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "gm_cv.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set and compute metrics\n",
    "y_pred = gm_cv.predict(X_test)\n",
    "r2 = gm_cv.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\n",
    "print(\"Tuned ElasticNet R squared: {}\".format(r2))\n",
    "print(\"Tuned ElasticNet MSE: {}\".format(mse))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
